---
layout: post
title:  Nginx架构
categories: Nginx
description: Nginx架构
keywords: Nginx架构
---
# Nginx框架

Nginx在启动后，在Unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。所以Nginx是以多进程的方式来工作的。
master进程主要用来管理worker进程，包含:接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重启新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程之间是相互独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其他进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器CPU核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。Nginx的进程模型，如下图：

![PNG](images/Nginx进程模型.png)

## master进程
master进程用来管理worker进程，所以我们只需要与master进程通信就可以了。master进程会接收来自外界发来的信号，再根据信号做不同的事情。比如kill -HUP pid，是告诉Nginx，从容的重启nginx，服务是不中断的。因为master进程在接到信号之后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。比如nginx -s reload。

## worker进程
worker进程之间是平等的，每个进程处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个请求都可能处理这个连接。首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket(listenfd)之后，然后再fork出多个worker进程。所有的worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该链接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接。这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。

#### 进程模型的好处

```
对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销；
同时在编程以及问题查找时，也会方便很多。
其次，采用独立的进程，可以让互相之间不受影响，
一个进程退出后，其他进程还在工作，服务不会中断，master进程可以很快启动新的worker进程
```

#### 关于accpet_mutex
此参数默认激活。对于此参数的定义如下：

```
当一个新连接到达时，如果激活了accept_mutex，那么多个worker将以串行方式来处理，
其中有一个worker会被唤醒，其他的worker继续保持休眠状态；
如果没有激活accetp_mutex，那么所有的worker都会被唤醒，
不过只有一个worker能获取新连接，其他的worker会重新进入休眠状态，这就是【惊群问题】。
Nginx默认激活了accept_mutex,是一种保守的选择。
如果关闭了它，可能会引起一定程度的惊群问题，表现为上下文切换增多"sar -w"或者负载上升；
但是如果网站访问量比较大，为了系统吞吐量，可以关闭此参数。
建议开启此参数：因为每台Nginx服务器启动worker个数一般不会太多，只有几个worker。
```

## 异步非阻塞

关于同步、异步、阻塞、非阻塞请移步[怎样理解阻塞非阻塞与同步异步的区别？](https://www.zhihu.com/question/19732473)

Nginx的高明之处就在于使用了异步非阻塞，虽然每个worker里面只有一个主线程，但是nginx是可以同时处理成千上万个请求的。首先一个请求的完整过程如下：首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式调用，那就得阻塞调用了。事件没有准备好，只能等待，等事件准备好了，才能继续。阻塞调用会进入内核等待，CPU就会让出去给别人用了，对单线程的worker来说，显然不合适。当网络事件越多时，大家都在等待，CPU闲下来没有线程使用，CPU利用率就会非常的低。当然，如果我们选择增加进程数，那么就会增加无谓的上下文切换。所以，只能选择使用非阻塞了。非阻塞就是，事件还没有准备好，马上返回EAGAIN，告诉你，事件还没准备好，等会再来吧。在此期间，你可以先去做其他事情，然后再时不时回来检查一下事件的状态，太麻烦了，如果事件好了之后通知我不就好了？然后就有了异步非阻塞的事件处理机制，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。以epoll为例，当事件还没准备好时，放到epoll里，事件准备好了，我们就去处理，当读写返回EAGAIN时，我们将他再次加入到epoll里。这样，只要事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才会在epoll里等待。这样，我们就可以处理大量并发请求了。


```
参考
http://tengine.taobao.org/book/chapter_02.html#id1

```
